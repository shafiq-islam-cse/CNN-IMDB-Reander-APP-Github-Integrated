# -*- coding: utf-8 -*-
"""CNN-IMDB-Firebase-Mobiel-App.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12g0XDW50iLUIszlEq_IIksSLccMKt9ov
"""

# STEP 1: Install libraries
#!pip install tensorflow tensorflow_datasets

# STEP 2: Load IMDB dataset
import tensorflow as tf
import tensorflow_datasets as tfds

(ds_train, ds_test), ds_info = tfds.load(
    'imdb_reviews',
    split=['train', 'test'],
    as_supervised=True,
    with_info=True
)

# STEP 3: Prepare tokenizer & vectorizer
max_features = 10000
sequence_length = 500

vectorize_layer = tf.keras.layers.TextVectorization(
    max_tokens=max_features,
    output_mode='int',
    output_sequence_length=sequence_length
)

# Fit on training data
train_text = ds_train.map(lambda x, y: x)
vectorize_layer.adapt(train_text)

# STEP 4: Prepare data pipeline
def vectorize_text(text, label):
    return vectorize_layer(text), label  # no need to expand dims

ds_train = ds_train.map(vectorize_text).batch(32).prefetch(tf.data.AUTOTUNE)
ds_test = ds_test.map(vectorize_text).batch(32).prefetch(tf.data.AUTOTUNE)

# STEP 5: CNN model
model = tf.keras.Sequential([
    tf.keras.Input(shape=(sequence_length,)),  # explicitly define input shape
    tf.keras.layers.Embedding(max_features + 1, 64),
    tf.keras.layers.Conv1D(64, 5, activation='relu'),
    tf.keras.layers.GlobalMaxPooling1D(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(ds_train, epochs=2, validation_data=ds_test)

# STEP 6: Save the model
model.save('cnn_imdb_model.h5')
model.save('cnn_imdb_model.keras')
#model.save('cnn_imdb_model')#Save model in a folder